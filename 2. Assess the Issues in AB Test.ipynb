{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the AB Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Channel KLMN runs a TV commercial featuring the Mayor of Los Angeles nationwide to promote its political talk show \"US Politics This Week\" and it is found this commercial only works for people residing in Los Angeles. \n",
    "* The Executive Producer of “US Politics This Week” suggested to add commercials featuring Mayors of local cities to the existing TV commercial (featuring the Mayor of Los Angeles).\n",
    "* After launching the new commercials, along with the old commercial, an AB Test found that: a lower fraction of people who saw the new commercials watched “US Politics This Week” as compared to people who saw the old commercial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reproduce the negative result found above. Is it actually negative?\n",
    "* Explain what might be happening. Are the commercials with local Mayors really driving a lower fraction of people to watch the show?\n",
    "* If you found something wrong with the experiment, design an algorithm that returns FALSE if the problem happens again in the future. If you didn’t find anything wrong, what is your recommendation to the Executive Producer regarding whether or not they should continue airing the new commercials?\n",
    "* Other thoughts and suggestions to improve the A/B test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import tree\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# plt.rc('figure', figsize=(3.0, 3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_data = pd.read_csv(\"../dataset/viewer_data.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test_data.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1918165</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27662619</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5493662</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>Detroit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14441247</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25595927</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   viewer_id  gender  age      city\n",
       "0    1918165  Female   39    Dallas\n",
       "1   27662619  Female   28  New York\n",
       "2    5493662  Female   53   Detroit\n",
       "3   14441247    Male   41  New York\n",
       "4   25595927    Male   53   Seattle"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tv_make</th>\n",
       "      <th>tv_size</th>\n",
       "      <th>uhd_capable</th>\n",
       "      <th>tv_provider</th>\n",
       "      <th>total_time_watched</th>\n",
       "      <th>watched</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24726768</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>Sony</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001464</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>Sony</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28291998</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>Sony</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Dish Network</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17057157</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>Sony</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29504447</td>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>Sony</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   viewer_id       date tv_make  tv_size  uhd_capable   tv_provider  \\\n",
       "0   24726768 2018-01-16    Sony       70            0       Comcast   \n",
       "1   25001464 2018-01-18    Sony       32            0           NaN   \n",
       "2   28291998 2018-01-18    Sony       50            1  Dish Network   \n",
       "3   17057157 2018-01-19    Sony       32            0       Comcast   \n",
       "4   29504447 2018-01-17    Sony       32            0       Comcast   \n",
       "\n",
       "   total_time_watched  watched  test  \n",
       "0               10.75        0     1  \n",
       "1                2.75        0     0  \n",
       "2               20.00        0     0  \n",
       "3                1.50        0     0  \n",
       "4               17.50        0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.ProfileReport(viewer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.ProfileReport(test_data[test_data.columns[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Investigation of the AB Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Part 1. Reproduce the Negative Result Found in the AB Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tv_make</th>\n",
       "      <th>tv_size</th>\n",
       "      <th>uhd_capable</th>\n",
       "      <th>tv_provider</th>\n",
       "      <th>total_time_watched</th>\n",
       "      <th>watched</th>\n",
       "      <th>test</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24726768</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>Sony</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001464</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>Sony</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   viewer_id       date tv_make  tv_size  uhd_capable tv_provider  \\\n",
       "0   24726768 2018-01-16    Sony       70            0     Comcast   \n",
       "1   25001464 2018-01-18    Sony       32            0         NaN   \n",
       "\n",
       "   total_time_watched  watched  test gender  age      city  \n",
       "0               10.75        0     1   Male   52    Boston  \n",
       "1                2.75        0     0   Male   38  New York  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(test_data, viewer_data, on=\"viewer_id\")\n",
    "merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204327 213143 0.04577955923593064 0.06309379149209686 0.05579781428788168\n"
     ]
    }
   ],
   "source": [
    "#  two-sample z-test of proportions:\n",
    "n1 = merged[merged.test == 1].shape[0] # number of commercial viewers in experiment group\n",
    "n2 = merged[merged.test == 0].shape[0] # number of commercial viewers in control group\n",
    "p1 = merged[merged.test == 1].watched.sum() / n1 # proportion of show watchers in experiment group\n",
    "p2 = merged[merged.test == 0].watched.sum() / n2 # proportion of show watchers in control group\n",
    "\n",
    "p_pool = merged.watched.sum() / (n1 + n1) # pooled propportion of show watchers\n",
    "print(n1, n2, p1, p2, p_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z statistic: -24.363963\n",
      "p value: 4.123635E-131\n"
     ]
    }
   ],
   "source": [
    "z = (p1 - p2) / np.sqrt(p_pool * (1 - p_pool) * (1 / n1 + 1 / n2))\n",
    "p_value = stats.norm.cdf(z) * 2\n",
    "print(\"z statistic: {0:.6f}\".format(z))\n",
    "print(\"p value: {0:.6E}\".format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the reprodduction of the AB test. Since z = -24.36 < 0 and p_value << 0.05, the AB test result shows the experiment group (the audience who viewed the new commercials involving local Mayors) has a statistically significantly smaller proportion of commercial viewers that susequently watched the show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2. Explain what might be happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment here should be a random control trial, which means subjects/experiment units are randomly allocated to two treatment groups (control and test), making the distributions of characteristic of subjects exactly the same between the control and test grouops. If the random treatment assignment mechnism works, the values of variable \"test\" shouldn't be explained by any the covariates (there shouldn't be confounders). Now we can use a decision tree to see how well the covariates are with regards of explaining if a subject is assigned to the test group vs to the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tv_make</th>\n",
       "      <th>tv_size</th>\n",
       "      <th>uhd_capable</th>\n",
       "      <th>tv_provider</th>\n",
       "      <th>total_time_watched</th>\n",
       "      <th>watched</th>\n",
       "      <th>test</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24726768</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>Sony</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001464</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>Sony</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28291998</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>Sony</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Dish Network</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17057157</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>Sony</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29504447</td>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>Sony</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>Detroit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   viewer_id       date tv_make  tv_size  uhd_capable   tv_provider  \\\n",
       "0   24726768 2018-01-16    Sony       70            0       Comcast   \n",
       "1   25001464 2018-01-18    Sony       32            0           NaN   \n",
       "2   28291998 2018-01-18    Sony       50            1  Dish Network   \n",
       "3   17057157 2018-01-19    Sony       32            0       Comcast   \n",
       "4   29504447 2018-01-17    Sony       32            0       Comcast   \n",
       "\n",
       "   total_time_watched  watched  test  gender  age           city  \n",
       "0               10.75        0     1    Male   52         Boston  \n",
       "1                2.75        0     0    Male   38       New York  \n",
       "2               20.00        0     0  Female   38  San Francisco  \n",
       "3                1.50        0     0    Male   39   Philadelphia  \n",
       "4               17.50        0     0  Female   57        Detroit  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged[[\"date\", \"tv_make\", \"tv_size\", \"uhd_capable\", \"tv_provider\", \"total_time_watched\", \"gender\", \"age\", \"city\"]]\n",
    "X[\"date\"] = X.date.dt.strftime('%Y-%m-%d')\n",
    "X[\"uhd_capable\"] = X.uhd_capable.astype(str)\n",
    "X = pd.get_dummies(X)\n",
    "y = merged[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"723pt\" height=\"520pt\"\n",
       " viewBox=\"0.00 0.00 722.50 520.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 516)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-516 718.5,-516 718.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#fefaf7\" stroke=\"#000000\" d=\"M538,-512C538,-512 387,-512 387,-512 381,-512 375,-506 375,-500 375,-500 375,-441 375,-441 375,-435 381,-429 387,-429 387,-429 538,-429 538,-429 544,-429 550,-435 550,-441 550,-441 550,-500 550,-500 550,-506 544,-512 538,-512\"/>\n",
       "<text text-anchor=\"start\" x=\"392\" y=\"-496.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">city_Los Angeles ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"433.5\" y=\"-481.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"405\" y=\"-466.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 417470</text>\n",
       "<text text-anchor=\"start\" x=\"383\" y=\"-451.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [213143, 204327]</text>\n",
       "<text text-anchor=\"start\" x=\"416\" y=\"-436.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Control</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#d5eaf9\" stroke=\"#000000\" d=\"M453,-393C453,-393 302,-393 302,-393 296,-393 290,-387 290,-381 290,-381 290,-322 290,-322 290,-316 296,-310 302,-310 302,-310 453,-310 453,-310 459,-310 465,-316 465,-322 465,-322 465,-381 465,-381 465,-387 459,-393 453,-393\"/>\n",
       "<text text-anchor=\"start\" x=\"307.5\" y=\"-377.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">city_Philadelphia ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"341\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.493</text>\n",
       "<text text-anchor=\"start\" x=\"320\" y=\"-347.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 364957</text>\n",
       "<text text-anchor=\"start\" x=\"298\" y=\"-332.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [160630, 204327]</text>\n",
       "<text text-anchor=\"start\" x=\"339.5\" y=\"-317.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Test</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M432.7711,-428.8796C426.4667,-420.0534 419.749,-410.6485 413.2476,-401.5466\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"416.0163,-399.4011 407.3558,-393.2981 410.3201,-403.4698 416.0163,-399.4011\"/>\n",
       "<text text-anchor=\"middle\" x=\"403.2458\" y=\"-414.2579\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 270716 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>270716</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M599.5,-385.5C599.5,-385.5 495.5,-385.5 495.5,-385.5 489.5,-385.5 483.5,-379.5 483.5,-373.5 483.5,-373.5 483.5,-329.5 483.5,-329.5 483.5,-323.5 489.5,-317.5 495.5,-317.5 495.5,-317.5 599.5,-317.5 599.5,-317.5 605.5,-317.5 611.5,-323.5 611.5,-329.5 611.5,-329.5 611.5,-373.5 611.5,-373.5 611.5,-379.5 605.5,-385.5 599.5,-385.5\"/>\n",
       "<text text-anchor=\"start\" x=\"518.5\" y=\"-370.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"493.5\" y=\"-355.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 52513</text>\n",
       "<text text-anchor=\"start\" x=\"491.5\" y=\"-340.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [52513, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"501\" y=\"-325.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Control</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;270716 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>0&#45;&gt;270716</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M492.2289,-428.8796C500.2403,-417.6636 508.9192,-405.5131 516.9734,-394.2372\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"520.025,-395.9866 522.9893,-385.8149 514.3288,-391.9179 520.025,-395.9866\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.0993\" y=\"-406.7748\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e5f2fc\" stroke=\"#000000\" d=\"M353,-274C353,-274 202,-274 202,-274 196,-274 190,-268 190,-262 190,-262 190,-203 190,-203 190,-197 196,-191 202,-191 202,-191 353,-191 353,-191 359,-191 365,-197 365,-203 365,-203 365,-262 365,-262 365,-268 359,-274 353,-274\"/>\n",
       "<text text-anchor=\"start\" x=\"223.5\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">city_Seattle ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"241\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.498</text>\n",
       "<text text-anchor=\"start\" x=\"220\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 336201</text>\n",
       "<text text-anchor=\"start\" x=\"198\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [156369, 179832]</text>\n",
       "<text text-anchor=\"start\" x=\"239.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Test</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M342.5249,-309.8796C334.9565,-300.8733 326.8819,-291.2644 319.088,-281.9897\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.7374,-279.7022 312.6244,-274.2981 316.3784,-284.2056 321.7374,-279.7022\"/>\n",
       "</g>\n",
       "<!-- 257033 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>257033</title>\n",
       "<path fill=\"#5baeea\" stroke=\"#000000\" d=\"M559.5,-274C559.5,-274 395.5,-274 395.5,-274 389.5,-274 383.5,-268 383.5,-262 383.5,-262 383.5,-203 383.5,-203 383.5,-197 389.5,-191 395.5,-191 395.5,-191 559.5,-191 559.5,-191 565.5,-191 571.5,-197 571.5,-203 571.5,-203 571.5,-262 571.5,-262 571.5,-268 565.5,-274 559.5,-274\"/>\n",
       "<text text-anchor=\"start\" x=\"391.5\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">total_time_watched ≤ 6.625</text>\n",
       "<text text-anchor=\"start\" x=\"441\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.252</text>\n",
       "<text text-anchor=\"start\" x=\"423.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 28756</text>\n",
       "<text text-anchor=\"start\" x=\"409.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4261, 24495]</text>\n",
       "<text text-anchor=\"start\" x=\"439.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Test</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;257033 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1&#45;&gt;257033</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M412.4751,-309.8796C420.0435,-300.8733 428.1181,-291.2644 435.912,-281.9897\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"438.6216,-284.2056 442.3756,-274.2981 433.2626,-279.7022 438.6216,-284.2056\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#f2f9fd\" stroke=\"#000000\" d=\"M163,-155C163,-155 12,-155 12,-155 6,-155 0,-149 0,-143 0,-143 0,-84 0,-84 0,-78 6,-72 12,-72 12,-72 163,-72 163,-72 169,-72 175,-78 175,-84 175,-84 175,-143 175,-143 175,-149 169,-155 163,-155\"/>\n",
       "<text text-anchor=\"start\" x=\"16.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">date_2018&#45;01&#45;16 ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"51\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.499</text>\n",
       "<text text-anchor=\"start\" x=\"30\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 317505</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [153523, 163982]</text>\n",
       "<text text-anchor=\"start\" x=\"49.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Test</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M211.0472,-190.8796C195.4267,-181.0962 178.671,-170.6019 162.6971,-160.5971\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.2481,-157.4387 153.9153,-155.0969 160.5324,-163.3712 164.2481,-157.4387\"/>\n",
       "</g>\n",
       "<!-- 248136 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>248136</title>\n",
       "<path fill=\"#5dafea\" stroke=\"#000000\" d=\"M360,-155C360,-155 205,-155 205,-155 199,-155 193,-149 193,-143 193,-143 193,-84 193,-84 193,-78 199,-72 205,-72 205,-72 360,-72 360,-72 366,-72 372,-78 372,-84 372,-84 372,-143 372,-143 372,-149 366,-155 360,-155\"/>\n",
       "<text text-anchor=\"start\" x=\"201\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tv_provider_DirecTV ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"246\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.258</text>\n",
       "<text text-anchor=\"start\" x=\"228.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18696</text>\n",
       "<text text-anchor=\"start\" x=\"214.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2846, 15850]</text>\n",
       "<text text-anchor=\"start\" x=\"244.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Test</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;248136 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;248136</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M279.2488,-190.8796C279.5931,-182.6838 279.9584,-173.9891 280.3151,-165.5013\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"283.8208,-165.4362 280.7438,-155.2981 276.827,-165.1423 283.8208,-165.4362\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M66.5,-36C66.5,-36 36.5,-36 36.5,-36 30.5,-36 24.5,-30 24.5,-24 24.5,-24 24.5,-12 24.5,-12 24.5,-6 30.5,0 36.5,0 36.5,0 66.5,0 66.5,0 72.5,0 78.5,-6 78.5,-12 78.5,-12 78.5,-24 78.5,-24 78.5,-30 72.5,-36 66.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M71.8146,-71.8901C68.4739,-63.0279 65.025,-53.8788 61.9386,-45.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.1877,-44.3878 58.3853,-36.2651 58.6376,-46.8569 65.1877,-44.3878\"/>\n",
       "</g>\n",
       "<!-- 198997 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>198997</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M138.5,-36C138.5,-36 108.5,-36 108.5,-36 102.5,-36 96.5,-30 96.5,-24 96.5,-24 96.5,-12 96.5,-12 96.5,-6 102.5,0 108.5,0 108.5,0 138.5,0 138.5,0 144.5,0 150.5,-6 150.5,-12 150.5,-12 150.5,-24 150.5,-24 150.5,-30 144.5,-36 138.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;198997 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;198997</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103.1854,-71.8901C106.5261,-63.0279 109.975,-53.8788 113.0614,-45.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.3624,-46.8569 116.6147,-36.2651 109.8123,-44.3878 116.3624,-46.8569\"/>\n",
       "</g>\n",
       "<!-- 248137 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>248137</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M275.5,-36C275.5,-36 245.5,-36 245.5,-36 239.5,-36 233.5,-30 233.5,-24 233.5,-24 233.5,-12 233.5,-12 233.5,-6 239.5,0 245.5,0 245.5,0 275.5,0 275.5,0 281.5,0 287.5,-6 287.5,-12 287.5,-12 287.5,-24 287.5,-24 287.5,-30 281.5,-36 275.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"260.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 248136&#45;&gt;248137 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>248136&#45;&gt;248137</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M272.9145,-71.8901C270.9178,-63.2227 268.8579,-54.2808 267.0038,-46.2325\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"270.3633,-45.2241 264.7077,-36.2651 263.5419,-46.7956 270.3633,-45.2241\"/>\n",
       "</g>\n",
       "<!-- 256170 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>256170</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M347.5,-36C347.5,-36 317.5,-36 317.5,-36 311.5,-36 305.5,-30 305.5,-24 305.5,-24 305.5,-12 305.5,-12 305.5,-6 311.5,0 317.5,0 317.5,0 347.5,0 347.5,0 353.5,0 359.5,-6 359.5,-12 359.5,-12 359.5,-24 359.5,-24 359.5,-30 353.5,-36 347.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 248136&#45;&gt;256170 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>248136&#45;&gt;256170</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M304.2853,-71.8901C309.0272,-62.8331 313.9259,-53.4765 318.2839,-45.1528\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.3995,-46.7478 322.9371,-36.2651 315.198,-43.5009 321.3995,-46.7478\"/>\n",
       "</g>\n",
       "<!-- 257034 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>257034</title>\n",
       "<path fill=\"#5dafea\" stroke=\"#000000\" d=\"M532.5,-155C532.5,-155 412.5,-155 412.5,-155 406.5,-155 400.5,-149 400.5,-143 400.5,-143 400.5,-84 400.5,-84 400.5,-78 406.5,-72 412.5,-72 412.5,-72 532.5,-72 532.5,-72 538.5,-72 544.5,-78 544.5,-84 544.5,-84 544.5,-143 544.5,-143 544.5,-149 538.5,-155 532.5,-155\"/>\n",
       "<text text-anchor=\"start\" x=\"439\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">age ≤ 71.5</text>\n",
       "<text text-anchor=\"start\" x=\"436\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.261</text>\n",
       "<text text-anchor=\"start\" x=\"422.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 9867</text>\n",
       "<text text-anchor=\"start\" x=\"408.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1522, 8345]</text>\n",
       "<text text-anchor=\"start\" x=\"434.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Test</text>\n",
       "</g>\n",
       "<!-- 257033&#45;&gt;257034 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>257033&#45;&gt;257034</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M475.7512,-190.8796C475.4069,-182.6838 475.0416,-173.9891 474.6849,-165.5013\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.173,-165.1423 474.2562,-155.2981 471.1792,-165.4362 478.173,-165.1423\"/>\n",
       "</g>\n",
       "<!-- 261861 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>261861</title>\n",
       "<path fill=\"#5baee9\" stroke=\"#000000\" d=\"M702.5,-155C702.5,-155 574.5,-155 574.5,-155 568.5,-155 562.5,-149 562.5,-143 562.5,-143 562.5,-84 562.5,-84 562.5,-78 568.5,-72 574.5,-72 574.5,-72 702.5,-72 702.5,-72 708.5,-72 714.5,-78 714.5,-84 714.5,-84 714.5,-143 714.5,-143 714.5,-149 708.5,-155 702.5,-155\"/>\n",
       "<text text-anchor=\"start\" x=\"605\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">age ≤ 56.5</text>\n",
       "<text text-anchor=\"start\" x=\"602\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.248</text>\n",
       "<text text-anchor=\"start\" x=\"584.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18889</text>\n",
       "<text text-anchor=\"start\" x=\"570.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2739, 16150]</text>\n",
       "<text text-anchor=\"start\" x=\"600.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Test</text>\n",
       "</g>\n",
       "<!-- 257033&#45;&gt;261861 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>257033&#45;&gt;261861</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M533.81,-190.8796C546.8012,-181.2774 560.719,-170.9903 574.0277,-161.1534\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"576.2604,-163.8555 582.2218,-155.0969 572.0996,-158.2263 576.2604,-163.8555\"/>\n",
       "</g>\n",
       "<!-- 257035 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>257035</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M437.5,-36C437.5,-36 407.5,-36 407.5,-36 401.5,-36 395.5,-30 395.5,-24 395.5,-24 395.5,-12 395.5,-12 395.5,-6 401.5,0 407.5,0 407.5,0 437.5,0 437.5,0 443.5,0 449.5,-6 449.5,-12 449.5,-12 449.5,-24 449.5,-24 449.5,-30 443.5,-36 437.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"422.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 257034&#45;&gt;257035 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>257034&#45;&gt;257035</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M450.7147,-71.8901C445.9728,-62.8331 441.0741,-53.4765 436.7161,-45.1528\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.802,-43.5009 432.0629,-36.2651 433.6005,-46.7478 439.802,-43.5009\"/>\n",
       "</g>\n",
       "<!-- 261828 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>261828</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M509.5,-36C509.5,-36 479.5,-36 479.5,-36 473.5,-36 467.5,-30 467.5,-24 467.5,-24 467.5,-12 467.5,-12 467.5,-6 473.5,0 479.5,0 479.5,0 509.5,0 509.5,0 515.5,0 521.5,-6 521.5,-12 521.5,-12 521.5,-24 521.5,-24 521.5,-30 515.5,-36 509.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 257034&#45;&gt;261828 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>257034&#45;&gt;261828</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M482.0855,-71.8901C484.0822,-63.2227 486.1421,-54.2808 487.9962,-46.2325\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"491.4581,-46.7956 490.2923,-36.2651 484.6367,-45.2241 491.4581,-46.7956\"/>\n",
       "</g>\n",
       "<!-- 261862 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>261862</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M617.5,-36C617.5,-36 587.5,-36 587.5,-36 581.5,-36 575.5,-30 575.5,-24 575.5,-24 575.5,-12 575.5,-12 575.5,-6 581.5,0 587.5,0 587.5,0 617.5,0 617.5,0 623.5,0 629.5,-6 629.5,-12 629.5,-12 629.5,-24 629.5,-24 629.5,-30 623.5,-36 617.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"602.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 261861&#45;&gt;261862 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>261861&#45;&gt;261862</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M622.8146,-71.8901C619.4739,-63.0279 616.025,-53.8788 612.9386,-45.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"616.1877,-44.3878 609.3853,-36.2651 609.6376,-46.8569 616.1877,-44.3878\"/>\n",
       "</g>\n",
       "<!-- 269729 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>269729</title>\n",
       "<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M689.5,-36C689.5,-36 659.5,-36 659.5,-36 653.5,-36 647.5,-30 647.5,-24 647.5,-24 647.5,-12 647.5,-12 647.5,-6 653.5,0 659.5,0 659.5,0 689.5,0 689.5,0 695.5,0 701.5,-6 701.5,-12 701.5,-12 701.5,-24 701.5,-24 701.5,-30 695.5,-36 689.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"674.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 261861&#45;&gt;269729 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>261861&#45;&gt;269729</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M654.1854,-71.8901C657.5261,-63.0279 660.975,-53.8788 664.0614,-45.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"667.3624,-46.8569 667.6147,-36.2651 660.8123,-44.3878 667.3624,-46.8569\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a28fe8fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, max_depth=3,\n",
    "                     feature_names=list(X.columns),  \n",
    "                     class_names=[\"Control\", \"Test\"],  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, it is found a sample from \"Los Angeles\" is 100% predicted to be a sample from the test group.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28811.198999999993"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_impurity_LA = (0.5*417470 - 0.493 * 364957 + 0 * 52513)\n",
    "reduced_impurity_LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5249.191000000009"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_impurity_Philly = (0.493*364957 - 0.498*336201 - 0.252*28756 )\n",
    "reduced_impurity_Philly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4169.535000000003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_impurity_Seattle = (0.498*336201 - 0.499*317505 - 0.258*18696)\n",
    "reduced_impurity_Seattle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.247000000000298"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_impurity_ttwatched = (0.252*28756 - 0.261*9867 - 0.248*18889)\n",
    "reduced_impurity_ttwatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the fitted decision tree, it is easy to find that some cities (Los Angeles, Philadelphia and Seattle) have imbalanced number of samples between test and control group, making them three major features to predict the treatment assignment. In other words, \"city\" is a confounder of \"test\" in this A/B test and it can lead to bias in the result of A/B test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do AB test for each city, except Los Angeles (this is because all viewers in the Los Angeles can only be categorized into the control group). And the z-satistic of the proportion test as well as the corresponding p value will be presented for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_z_test(df):\n",
    "    n1 = df[df.test == 1].shape[0] \n",
    "    n2 = df[df.test == 0].shape[0] \n",
    "    p1 = df[df.test == 1].watched.sum() / n1 \n",
    "    p2 = df[df.test == 0].watched.sum() / n2 \n",
    "    p_pool = df.watched.sum() / (n1 + n1) \n",
    "\n",
    "    z = (p1 - p2) / np.sqrt(p_pool * (1 - p_pool) * (1 / n1 + 1 / n2))\n",
    "    p_value = stats.norm.cdf(z) * 2 if z < 0 else (1-stats.norm.cdf(z)) * 2\n",
    "    s = pd.Series([ p_pool, z, p_value], index=[\"p_pool\",\"z_statistic\", \"p_value\"])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = merged[merged.city!=\"Los Angeles\"].groupby(\"city\").apply(two_sample_z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlanta</th>\n",
       "      <td>0.237036</td>\n",
       "      <td>0.812629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston</th>\n",
       "      <td>0.299507</td>\n",
       "      <td>0.764553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>0.930993</td>\n",
       "      <td>0.351857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dallas</th>\n",
       "      <td>-1.178892</td>\n",
       "      <td>0.238441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detroit</th>\n",
       "      <td>1.949756</td>\n",
       "      <td>0.051205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston</th>\n",
       "      <td>0.441955</td>\n",
       "      <td>0.658522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami</th>\n",
       "      <td>0.782176</td>\n",
       "      <td>0.434111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minneapolis</th>\n",
       "      <td>-0.208516</td>\n",
       "      <td>0.834826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>-1.837328</td>\n",
       "      <td>0.066162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philadelphia</th>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.997728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoenix</th>\n",
       "      <td>-0.678374</td>\n",
       "      <td>0.497535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco</th>\n",
       "      <td>-0.111468</td>\n",
       "      <td>0.911245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seattle</th>\n",
       "      <td>-0.971047</td>\n",
       "      <td>0.331525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tampa</th>\n",
       "      <td>0.343183</td>\n",
       "      <td>0.731461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               z_statistic   p_value\n",
       "city                                \n",
       "Atlanta           0.237036  0.812629\n",
       "Boston            0.299507  0.764553\n",
       "Chicago           0.930993  0.351857\n",
       "Dallas           -1.178892  0.238441\n",
       "Detroit           1.949756  0.051205\n",
       "Houston           0.441955  0.658522\n",
       "Miami             0.782176  0.434111\n",
       "Minneapolis      -0.208516  0.834826\n",
       "New York         -1.837328  0.066162\n",
       "Philadelphia      0.002847  0.997728\n",
       "Phoenix          -0.678374  0.497535\n",
       "San Francisco    -0.111468  0.911245\n",
       "Seattle          -0.971047  0.331525\n",
       "Tampa             0.343183  0.731461"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[[\"z_statistic\", \"p_value\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the individual AB tests show no significant difference in watching rate (proportion of commercial vieweres who will end up watching the tv show) in any of the cities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tv_make</th>\n",
       "      <th>tv_size</th>\n",
       "      <th>uhd_capable</th>\n",
       "      <th>tv_provider</th>\n",
       "      <th>total_time_watched</th>\n",
       "      <th>watched</th>\n",
       "      <th>test</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24726768</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>Sony</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   viewer_id       date tv_make  tv_size  uhd_capable tv_provider  \\\n",
       "0   24726768 2018-01-16    Sony       70            0     Comcast   \n",
       "\n",
       "   total_time_watched  watched  test gender  age    city  \n",
       "0               10.75        0     1   Male   52  Boston  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_group = merged[merged.test == 1]\n",
    "control_group = merged[merged.test == 0]\n",
    "test_group.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In below, I use \"views\" and \"number of observations\" interchangeably.\n",
    "test_cnt = test_group.groupby('city').size()\n",
    "df1 = test_cnt / test_group.shape[0]\n",
    "control_cnt = control_group.groupby('city').size()\n",
    "df2 = control_cnt / control_group.shape[0]\n",
    "nobs = pd.concat([test_cnt, control_cnt, df1, df2], axis=1)\n",
    "nobs.columns = [\"test_city_views\", \"control_city_views\", \"prop_to_test_views\", \"prop_to_control_views\"]\n",
    "nobs = nobs.fillna(0).round(4)\n",
    "nobs.test_city_views = nobs.test_city_views.astype(int)\n",
    "nobs[\"diff\"] = nobs.prop_to_test_views - nobs.prop_to_control_views\n",
    "p_pool = pd.DataFrame({\"p_pool\":merged.groupby(\"city\").apply(lambda df: df.watched.sum() / df.shape[0])})\n",
    "nobs = nobs.join(p_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_city_views</th>\n",
       "      <th>control_city_views</th>\n",
       "      <th>prop_to_test_views</th>\n",
       "      <th>prop_to_control_views</th>\n",
       "      <th>diff</th>\n",
       "      <th>p_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Philadelphia</th>\n",
       "      <td>24495</td>\n",
       "      <td>4261</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.023473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seattle</th>\n",
       "      <td>15850</td>\n",
       "      <td>2846</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.026048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dallas</th>\n",
       "      <td>13807</td>\n",
       "      <td>12874</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.049286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco</th>\n",
       "      <td>12609</td>\n",
       "      <td>11691</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.049794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detroit</th>\n",
       "      <td>9192</td>\n",
       "      <td>8739</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.050137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atlanta</th>\n",
       "      <td>12599</td>\n",
       "      <td>11728</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.050561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>16991</td>\n",
       "      <td>16054</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.050598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami</th>\n",
       "      <td>8984</td>\n",
       "      <td>8301</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.050969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tampa</th>\n",
       "      <td>9631</td>\n",
       "      <td>8974</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.051492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>35812</td>\n",
       "      <td>34082</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.051492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston</th>\n",
       "      <td>12660</td>\n",
       "      <td>11758</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.051888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston</th>\n",
       "      <td>12589</td>\n",
       "      <td>11802</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.051986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoenix</th>\n",
       "      <td>10015</td>\n",
       "      <td>9317</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.052555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minneapolis</th>\n",
       "      <td>9093</td>\n",
       "      <td>8203</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.052787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>0</td>\n",
       "      <td>52513</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>-0.2464</td>\n",
       "      <td>0.103060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               test_city_views  control_city_views  prop_to_test_views  \\\n",
       "Philadelphia             24495                4261              0.1199   \n",
       "Seattle                  15850                2846              0.0776   \n",
       "Dallas                   13807               12874              0.0676   \n",
       "San Francisco            12609               11691              0.0617   \n",
       "Detroit                   9192                8739              0.0450   \n",
       "Atlanta                  12599               11728              0.0617   \n",
       "Chicago                  16991               16054              0.0832   \n",
       "Miami                     8984                8301              0.0440   \n",
       "Tampa                     9631                8974              0.0471   \n",
       "New York                 35812               34082              0.1753   \n",
       "Boston                   12660               11758              0.0620   \n",
       "Houston                  12589               11802              0.0616   \n",
       "Phoenix                  10015                9317              0.0490   \n",
       "Minneapolis               9093                8203              0.0445   \n",
       "Los Angeles                  0               52513              0.0000   \n",
       "\n",
       "               prop_to_control_views    diff    p_pool  \n",
       "Philadelphia                  0.0200  0.0999  0.023473  \n",
       "Seattle                       0.0134  0.0642  0.026048  \n",
       "Dallas                        0.0604  0.0072  0.049286  \n",
       "San Francisco                 0.0549  0.0068  0.049794  \n",
       "Detroit                       0.0410  0.0040  0.050137  \n",
       "Atlanta                       0.0550  0.0067  0.050561  \n",
       "Chicago                       0.0753  0.0079  0.050598  \n",
       "Miami                         0.0389  0.0051  0.050969  \n",
       "Tampa                         0.0421  0.0050  0.051492  \n",
       "New York                      0.1599  0.0154  0.051492  \n",
       "Boston                        0.0552  0.0068  0.051888  \n",
       "Houston                       0.0554  0.0062  0.051986  \n",
       "Phoenix                       0.0437  0.0053  0.052555  \n",
       "Minneapolis                   0.0385  0.0060  0.052787  \n",
       "Los Angeles                   0.2464 -0.2464  0.103060  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobs.sort_values(\"p_pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atlanta            871\n",
       "Boston             902\n",
       "Chicago            937\n",
       "Dallas             933\n",
       "Detroit            453\n",
       "Houston            787\n",
       "Miami              683\n",
       "Minneapolis        890\n",
       "New York          1730\n",
       "Philadelphia     20234\n",
       "Phoenix            698\n",
       "San Francisco      918\n",
       "Seattle          13004\n",
       "Tampa              657\n",
       "Los Angeles     -52513\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobs.test_city_views - nobs.control_city_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that the number of observations in test and control groups are highly unbalanced given each city (except Los Angeles, all other cities are having more observations in the control group than the observations in the test group). It seems this is a consequence of the erroneous data collection process aming to balance the total number of observations in the test and control groups!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From another perspective, we can see that the distribution of views (by city) are drastically differerent between the test and control groups (see column \"prop_to_test_views\" and \"prop_to_control_views\"). In the test group, views are spread in the non-Los-Angeles cities where pooled watching rate are low (ranging from 0.023 to 0.053) and no view is present in Los Angeles; whereas in the control group, 24.64% views are from Los Angeles where the pooled watching rate is as high as 0.103, and less views are collected from lower watching rate cities. This is the exact setup of Simpson's Paradox! Here, it is the difference in distribution of city views (demographic composition) between the test and control groups, combined with the fact that different cities (demographics) have different overall watching rates (p_pool, Los Angeles vs others) that drives the misleading AB Test results.\n",
    "\n",
    "(In order to fix the above issue, we should first make sure the views or the viewers are balanced on all levels of all charateristics)\n",
    "\n",
    "At this stage, I suggest only trust the city-wise AB test results, which means, we found no enough evidence for any of the investigated city to conclude that the new commercial can help to change the watching rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Atlanta'),\n",
       " Text(1, 0, 'Boston'),\n",
       " Text(2, 0, 'Chicago'),\n",
       " Text(3, 0, 'Dallas'),\n",
       " Text(4, 0, 'Detroit'),\n",
       " Text(5, 0, 'Houston'),\n",
       " Text(6, 0, 'Los Angeles'),\n",
       " Text(7, 0, 'Miami'),\n",
       " Text(8, 0, 'Minneapolis'),\n",
       " Text(9, 0, 'New York'),\n",
       " Text(10, 0, 'Philadelphia'),\n",
       " Text(11, 0, 'Phoenix'),\n",
       " Text(12, 0, 'San Francisco'),\n",
       " Text(13, 0, 'Seattle'),\n",
       " Text(14, 0, 'Tampa')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Number of Observations in Different Cities (Test Group v.s. Control Group)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = pd.DataFrame({\"num_obs\": merged.groupby([\"test\", \"city\"]).size()}).reset_index()\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=sizes, kind=\"bar\",\n",
    "    x=\"city\", y=\"num_obs\", hue=\"test\",\n",
    "    ci=\"sd\", palette=\"dark\", alpha=.6, height=3.2 , aspect=1.5)\n",
    "\n",
    "for ax in g.axes.ravel():\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    \n",
    "g.fig.suptitle(\"Number of Observations in Different Cities (Test Group v.s. Control Group)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the visualized distribution of views across different cities, the differences of views in Los Angeles (52513 obs in the control group and 0 obs in the test group), Seattle (13004 more obs in the test group) and Philadelphia (20234 more obs in the test group) are quite offending. Inbalance of number of samples between test and control groups will lower the statistical power of the A/B test!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if there's any factor other than city will influence the watching rate (the value of watched), we can run a logistic regression model with the \"watched\" column as the label column and check the coefficient estimation (as well as their test results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"\"\"\n",
    "watched ~ C(date)+C(tv_make)+C(tv_size)+C(uhd_capable)+C(tv_provider) + total_time_watched + \n",
    "C(test) + C(gender) + age + C(city)\n",
    "\"\"\"\n",
    "model_fit = smf.glm(formula, merged, family = sm.families.Binomial()).fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the fitted model above is a simplified one where only main effects are investigated (no interaction terms considered). The test summary shows the following factors have statistically significant coefficients: Intercept, the 3 dates (2018-01-16, 2018-01-17, 2018-01-19), C(city)[T.Los Angeles], C(city)[T.Philadelphia] and C(city)[T.Seattle] have  This means:\n",
    "\n",
    "(1) Tuesday (2018-01-16), Wednesday(2018-01-17), and Friday (2018-01-19) have higher watching rate than Monday (2018-01-15, the reference level of the variable \"date\");\n",
    "\n",
    "(2) being a viewer from Los Angeles drives watching rate up; \n",
    "\n",
    "(3) being a viewer from Philadelphia & Seattle are drives watching rate down; \n",
    "\n",
    "(4) there's no strong enough evidence to show that adding the new commercials featuring local Mayors (see the p value of C(test)[T.1]) can help to change the watching rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3. Design an algorithm that returns FALSE if the problem happens again in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the experience tells only city is a factor that can influence watching rate, the algorithm required should check if the number of views (sample sizes) in the test and control groups are similar for each city. (If yes, we can at least do the AB test on city level.) There are three test to be done:\n",
    "(1) One-sample z-test of proportion to see, given sampled data from all cities, if the test group and control group have similar sizes.\n",
    "\n",
    "(2) Chi-square test of proportion, to test if distribution of views (among cities are different) are different between test group and control groups. \n",
    "\n",
    "And False will be returned if any of the test show significant difference between the test and control groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_data_validity:\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "        \n",
    "    def test_of_equal_sizes(self):\n",
    "        n1 = self.data[self.data.test == 1].shape[0]\n",
    "        n2 = self.data[self.data.test == 0].shape[0]\n",
    "        n = n1 + n2\n",
    "        p = 0.5\n",
    "        z = (n1 - n * p) / np.sqrt(n * p * (1 - p))\n",
    "        p = stats.norm.cdf(z) * 2 if z < 0 else (1 - stats.norm.cdf(z)) * 2\n",
    "        return z, p, False if p < 0.05 else True\n",
    "\n",
    "    def test_of_same_proportions(self):\n",
    "        sizes1 = self.data[self.data.test==1].groupby(\"city\").size()\n",
    "        sizes2 = self.data[self.data.test==0].groupby(\"city\").size()\n",
    "        obs = pd.concat([sizes1, sizes2], axis=1).dropna().values\n",
    "        chi2, p, dof, ex = stats.chi2_contingency(obs)\n",
    "        return chi2, p, False if p < 0.05 else True\n",
    "    \n",
    "    def data_sanity_check_result(self):\n",
    "        _, _, res1 = self.test_of_equal_sizes()\n",
    "        _, _, res2 = self.test_of_same_proportions()\n",
    "        \n",
    "        if res1 and res2:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_data_validity(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test_of_equal_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test_of_same_proportions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data_sanity_check_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sanity check code usage example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = test_data_validity(merged)\n",
    "obj.data_sanity_check_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4. Other thoughts and suggestions to improve the A/B test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. length of data collection periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = merged.groupby('test').apply(lambda df:df.groupby(\"date\").watched.mean()).T.plot(figsize=(4,2), style='o-')\n",
    "ax.set_ylabel('Conversion Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are differences in average conversion rates among different weekdays (appearing both in test and control groups), while these between-dates differences are much smaller than the differences observed across test and control group. \n",
    "\n",
    "However, the Saturday and Sunday conversion rates can be much more different than those in weekdays, and their test and control comparisons are also interesting information for the business. Thus, if the show \"US Politics This Week\" is also broadcased on weekends, we want to at least include a whole week for the A/B test; and we need to make sure the random assignment of treatments actually works so that equal/similar number of samples are collected on the test and control sides given each day of the week. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. power analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was tested on the city level that there's no effect of using the new type of commercials featuring local Mayors on the watching rate of political talk shows. Another possibility is that we don't have have large enough sample size to achieve the desired statistical power (probability to reject null hypothesis when the alternative hypothesis is true). \n",
    "\n",
    "So, we may also want to check the sample size in addition to the existing tests in the data validation procedure (see Part 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we assume there are equal number of samples in the test and control groups\n",
    "def get_sample_size(alpha,power,p, d):\n",
    "    sd1 = np.sqrt(2 * p * (1 - p))\n",
    "    sd2 = np.sqrt(p * (1 - p) + (p + d) * (1 - (p + d)))\n",
    "    n = (stats.norm.ppf(1-alpha/2)*sd1+stats.norm.ppf(power)*sd2)**2 / d**2\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = merged.watched.mean()\n",
    "n = get_sample_size(0.05, 0.8, p0, 0.01)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.groupby(\"city\").apply(lambda df: df.test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, we find, for an A/B test to detect a practically significant change of 1% in conversion rate (at a significance level of 0.95 and a power of 0.8), we need at least 8310 samples in each of the contral and test groups. \n",
    "\n",
    "In our case, the sample sizes in the control and test groups are large enough for the overall A/B test. However, the sample sizes of each groups are smaller than the desired value in some city-level experiments (Miami, Minneapolis, Los Angeles, Philadelphia and Seattle). More data should be collected from these cities if we want the relevant tests have desired statistical power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the test_sample_size method to the test_data_validity class for the overall A/B test, now I have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_data_validity:\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "        \n",
    "    def test_of_equal_sizes(self):\n",
    "        \"\"\"Test to ensure same size of test and control groups, in order to maximize the \n",
    "        statistical power of the A/B test.\"\"\"\n",
    "        n1 = self.data[self.data.test == 1].shape[0]\n",
    "        n2 = self.data[self.data.test == 0].shape[0]\n",
    "        n = n1 + n2\n",
    "        p = 0.5\n",
    "        z = (n1 - n * p) / np.sqrt(n * p * (1 - p))\n",
    "        p = stats.norm.cdf(z) * 2 if z < 0 else (1 - stats.norm.cdf(z)) * 2\n",
    "        if p < 0.05:\n",
    "            print(\"1. The data failed the following data validity check: test_of_equal_sizes.\")\n",
    "        else:\n",
    "            print(\"1. The data passed the following data validity check: test_of_equal_sizes.\")\n",
    "        return z, p, False if p < 0.05 else True\n",
    "\n",
    "    def test_of_same_proportions(self):\n",
    "        \"\"\"Test to ensure the same demographic composition of the test and control groups, in\n",
    "        order to avoid the bias as a result of the confounding between the treatment and the \n",
    "        demographic property.\n",
    "        \"\"\"\n",
    "        sizes1 = self.data[self.data.test==1].groupby(\"city\").size()\n",
    "        sizes2 = self.data[self.data.test==0].groupby(\"city\").size()\n",
    "        obs = pd.concat([sizes1, sizes2], axis=1).dropna().values\n",
    "        chi2, p, dof, ex = stats.chi2_contingency(obs)\n",
    "        if p < 0.05:\n",
    "            print(\"2. The data failed the following data validity check: test_of_same_proportions.\")\n",
    "        else:\n",
    "            print(\"2. The data passed the following data validity check: test_of_same_proportions.\")\n",
    "        return chi2, p, False if p < 0.05 else True\n",
    "    \n",
    "    def test_sample_size(self, alpha, power, d):\n",
    "        \"\"\"Check if the sample size (in the test or control group, assuming they have same sample sizes)\n",
    "        is large enough for the A/B test to have the desired power and effect size.\n",
    "        \"\"\"\n",
    "        p = self.data.watched.mean()\n",
    "        sd1 = np.sqrt(2 * p * (1 - p))\n",
    "        sd2 = np.sqrt(p * (1 - p) + (p + d) * (1 - (p + d)))\n",
    "        n = (stats.norm.ppf(1-alpha/2)*sd1+stats.norm.ppf(power)*sd2)**2 / d**2\n",
    "        x, y = self.data.test.value_counts()\n",
    "        if x < n or y < n:\n",
    "            print(\"3. The sample sizes (control: {}, test: {}) failed the following data validity check: test_sample_size.\\n   - The minimum sample size to detect a change of {}% in conversion rate given a significance level of {} and \\n   a power of {} is: {}.\".format(x, y, round(d*100,2), alpha, power, round(n)))\n",
    "        else:\n",
    "            print(\"3. The sample sizes (control: {}, test: {}) passed the following data validity check: test_sample_size.\\n   - The minimum sample size to detect a change of {}% in conversion rate given a significance level of {} and \\n   a power of {} is: {}.\".format(x, y, round(d*100,2), alpha, power, round(n)))\n",
    "        return False if x < n or y < n else True\n",
    "    \n",
    "    def data_sanity_check_result(self):\n",
    "        _, _, res1 = self.test_of_equal_sizes()\n",
    "        _, _, res2 = self.test_of_same_proportions()\n",
    "        res3 = self.test_sample_size(alpha=0.05, power=0.8, d=0.01)\n",
    "        \n",
    "        if res1 and res2 and res3:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = test_data_validity(merged)\n",
    "obj.data_sanity_check_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
